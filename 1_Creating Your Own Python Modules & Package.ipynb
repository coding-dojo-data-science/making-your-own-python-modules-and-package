{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Your Own Python Modules & Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 05/13/22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Reviewing Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Concepts to review:\n",
    "    - Defining Function Arguments/Parameters:\n",
    "        - Positional Arguments\n",
    "        - Keyword Arguments\n",
    "\n",
    "        - Return Statements\n",
    "\n",
    "    - Function Scope\n",
    "\n",
    "    - Docstrings\n",
    "    \n",
    "- We will start with some example code from the LP that would be perfect for a function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "url = 'https://docs.google.com/spreadsheets/d/1VMaw2oCn0ABitd-alLAEsEhGS1Je2UFNLu76TKrIH7w/gviz/tq?tqx=out:csv&sheet=Raw_Medical_Data_for_day1'\n",
    "df = pd.read_csv(url, index_col = 0)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code from: https://login.codingdojo.com/m/376/12533/89502\n",
    "col = 'Income'\n",
    "feature = df[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Turn the code below into a function:\n",
    "mean = feature.mean()\n",
    "median = feature.median()\n",
    "std = feature.std()\n",
    "plus_one_std = mean + std\n",
    "minus_one_std = mean - std\n",
    "fig,ax = plt.subplots(figsize=(10,6))\n",
    "sns.histplot(feature ,ax=ax,stat='probability')\n",
    "ax.axvline(plus_one_std, color = 'black',label=f'+1 std = {plus_one_std:,.2f}')\n",
    "ax.axvline(minus_one_std, color = 'black', label = f'-1 std = {minus_one_std:,.2f}')\n",
    "ax.axvspan(plus_one_std, minus_one_std, color = 'yellow', zorder = 0)\n",
    "ax.set_title(f'{col}')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">- Turn the above code into a function.\n",
    "    - Make it more flexible (e.g. be change figsize)\n",
    "    - Make it return the figure\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## turn the above code into a function\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Moving Your Functions to a Py File\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Move Code To an External File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Open the repository in VS Code. \n",
    "- Create a new py file in the same folder as the notebook (we will call ours `my_functions.py`)\n",
    "- Copy over the function(s) from your notebook into the .py file. \n",
    "    - Make sure to save the file after adding code.\n",
    "    \n",
    "- In your notebook, import the file (just drop the `.py`) by name,just like you do with pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    ">- Thanks to Alexis for letting me use her function as an example! \n",
    "    - Source: https://github.com/adeviney/data-enrichment-project/blob/main/Distributions/Describing%20Distributions.ipynb \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Source: https://github.com/adeviney/data-enrichment-project/blob/main/Distributions/Describing%20Distributions.ipynb \n",
    "def plot_function(df, feature):\n",
    "    \n",
    "    fig = plt.figure(figsize=(8, 6))\n",
    "    ax = sns.histplot(x=df[feature],kde=True)\n",
    "    mean = df[feature].mean()\n",
    "    median = df[feature].median()\n",
    "    std = df[feature].std()\n",
    "    ax.axvline(mean, color='r', label=f'Mean = {mean:,.2f}')\n",
    "    ax.axvline(median, color='g', label=f'Median = {median:,.2f}')\n",
    "    ax.axvline(mean-std, color = 'k', label = f'─1 StDev = {mean-std:,.2f}')\n",
    "    ax.axvline(mean+std, color = 'k', label = f'+1 StDev = {mean+std:,.2f}')\n",
    "    ax.axvspan(mean-std,mean+std,color = 'y',zorder = 0)\n",
    "    ax.set_title(feature);\n",
    "    ax.legend()\n",
    "    \n",
    "    \n",
    "    # Question Answers\n",
    "    print('Answers to Questions')\n",
    "    print('1. Is it Discrete or Continuous?')\n",
    "    if ((df.dtypes[feature] == 'float') & (df[feature].nunique()/ df[feature].count() > .90)):\n",
    "        #probably continuous\n",
    "        print(\"Continuous\")\n",
    "    else:\n",
    "        print(\"Discrete\")\n",
    "    print('\\n2. Does it have a skew? If so, which direction (+/-)')\n",
    "    skew = round(stats.skew(df[feature]),1)\n",
    "    skew_class = 'Normal; no skew' if skew == 0 else 'Negative Skew' if skew < 0 else 'Positive Skew'\n",
    "    print(skew_class)\n",
    "    \n",
    "    print('\\n3. What type of kurtosis does it display? (Mesokurtic, Leptokurtic, Platykurtic)')\n",
    "    kurt_val = stats.kurtosis(df[feature], fisher = False)\n",
    "    kurt_class = 'Mesokurtic' if round(kurt_val,1) == 3 else 'Leptokurtic' if kurt_val > 3 else 'Platykurtic'\n",
    "    print(f'kurtosis = {kurt_val:.2f}, {kurt_class}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://docs.google.com/spreadsheets/d/1APV3pXiAszS_0mSgkiEt9IUNH-QmyX7KwxSAwuADl6Y/gviz/tq?tqx=out:csv&sheet=medical_data')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Auto-Reload \n",
    "- To flexibly work on updating your function inside VS Code and automatically updating the version that was imported into your notebook, we will use the autoreload extensions.\n",
    "- https://ipython.org/ipython-doc/3/config/extensions/autoreload.html\n",
    "\n",
    "```python\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-13T19:28:04.236145Z",
     "start_time": "2021-01-13T19:28:04.205223Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-13T19:30:51.022809Z",
     "start_time": "2021-01-13T19:30:50.994449Z"
    }
   },
   "outputs": [],
   "source": [
    "## Importing custom functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using `inspect` to show source code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-13T19:35:19.344036Z",
     "start_time": "2021-01-13T19:35:19.308542Z"
    }
   },
   "outputs": [],
   "source": [
    "import inspect\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "\n",
    "# txt = inspect.getsource(mf.print_xy)\n",
    "# display(Markdown(\"```python\\n\"+txt+\"\\n```\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Making a Package with Sub-Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structuring Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use folders & `__init__.py` to define package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Official Packaging Tutorial](https://packaging.python.org/tutorials/packaging-projects/)\n",
    "- Our module is structure like this:\n",
    "```\n",
    "capstone_functions\n",
    "    └── __init__.py\n",
    "    └── my_functions.py\n",
    "    └── lz.py\n",
    "```\n",
    "\n",
    "- The folder can contain other py files as well, but its needs an __init__.py to be recognized as a package. \n",
    "- The other py files can be import inside of __init__.py to make them part of the namespace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Packaging Namespaces/Submodules](https://packaging.python.org/guides/packaging-namespace-packages/#packaging-namespace-packages)_\n",
    "\n",
    "- Contents of our __init__.py\n",
    "\n",
    "```python\n",
    "\"\"\"A collection of example functions for 081720FT cohort\n",
    "- James M. Irving, Ph.D.\n",
    "- james.irving.phd@gmail.com\"\"\"\n",
    "\n",
    "from capstone_functions import my_functions\n",
    "from capstone_functions import lz\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Python Package Folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create a folder in our repo (name of folder is name of package).\n",
    "    - Create a `__init__.py` file in the folder. \n",
    "    - Whatever we import into the init file will appear in our package.\n",
    "    - Store functions in modules/py files.\n",
    "        - .py file names are sub-module name/ \n",
    "        - e.g. from sklearn.**preprocessing** import StandardScaler()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, make a `statistics` module\n",
    "- Include our original function\n",
    "- Add the following functions:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "def find_outliers_Z(data, verbose=True):\n",
    "    outliers = np.abs(stats.zscore(data))>3\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"- {outliers.sum()} outliers found in {data.name} using Z-Scores.\")\n",
    "    return outliers\n",
    "\n",
    "\n",
    "def find_outliers_IQR(data, verbose=True):\n",
    "    q3 = np.quantile(data,.75)\n",
    "    q1 = np.quantile(data,.25)\n",
    "\n",
    "    IQR = q3 - q1\n",
    "    upper_threshold = q3 + 1.5*IQR\n",
    "    lower_threshold = q1 - 1.5*IQR\n",
    "    \n",
    "    outliers = (data<lower_threshold) | (data>upper_threshold)\n",
    "    if verbose:\n",
    "        print(f\"- {outliers.sum()} outliers found in {data.name} using IQR.\")\n",
    "        \n",
    "    return outliers\n",
    "\n",
    "\n",
    "def evaluate_ols(result,X_train_df, y_train, show_summary=True):\n",
    "    \"\"\"Plots a Q-Q Plot and residual plot for a statsmodels OLS regression.\n",
    "    \"\"\"\n",
    "    if show_summary==True:\n",
    "        try:\n",
    "            display(result.summary())\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    ## save residuals from result\n",
    "    y_pred = result.predict(X_train_df)\n",
    "    resid = y_train - y_pred\n",
    "    \n",
    "    fig, axes = plt.subplots(ncols=2,figsize=(12,5))\n",
    "    \n",
    "    ## Normality \n",
    "    sm.graphics.qqplot(resid,line='45',fit=True,ax=axes[0]);\n",
    "    \n",
    "    ## Homoscedasticity\n",
    "    ax = axes[1]\n",
    "    ax.scatter(y_pred, resid, edgecolor='white',lw=1)\n",
    "    ax.axhline(0,zorder=0)\n",
    "    ax.set(ylabel='Residuals',xlabel='Predicted Value');\n",
    "    plt.tight_layout()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Also make a `sql` module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_credentials(filename, verbose=True):\n",
    "    import json\n",
    "    with open(filename) as f:\n",
    "        login = json.load(f)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"[i] Credentials loaded from: {filename}\")\n",
    "        print('- Keys:')\n",
    "        [print(f\"    - {k}\") for k in login.keys()]\n",
    "\n",
    "    return login\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_schema(table,debug=False):\n",
    "    from sqlalchemy.types import Text, Integer, Float, NullType, Boolean, String\n",
    "    ## save pandas dtypes in list, make empty dict\n",
    "    dtypes = table.dtypes\n",
    "    schema = {}\n",
    "    \n",
    "    # for each column\n",
    "    for col in dtypes.index:\n",
    "        ## print info if in debug mode\n",
    "        if debug:\n",
    "            print(f\"{col} = {dtypes.loc[col]}\")\n",
    "\n",
    "        ## if its a string column (object)\n",
    "        if dtypes.loc[col]=='object':\n",
    "            \n",
    "            ## Fill null values and make sure whole column is str\n",
    "            data = table[col].fillna('').astype(str)\n",
    "            \n",
    "            ## get len first\n",
    "            len_str = data.map(len).max()\n",
    "            \n",
    "            ## if the string is shorter than 21845 use String\n",
    "            # (forget how i knew it was max size)\n",
    "            if len_str < 21845:\n",
    "                schema[col] = String( len_str + 1)\n",
    "                \n",
    "            ## If longer use Text\n",
    "            else:\n",
    "                schema[col] = Text(len_str+1)\n",
    "        \n",
    "        # if float make Float\n",
    "        elif dtypes.loc[col] == 'float':\n",
    "            schema[col] = Float()\n",
    "\n",
    "        ## if int make Integer\n",
    "        elif dtypes.loc[col] == 'int':\n",
    "            schema[col] = Integer()\n",
    "            \n",
    "        ## if bool make Boolean\n",
    "        elif dtypes.loc[col] == 'bool':\n",
    "            schema[col] = Boolean()\n",
    "            \n",
    "    return schema\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3B: Using Your Package As-Is (Locally)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> NOTE: IF YOU PLAN ON TRYING PART 4: PUBLISHING A PACKAGE ON PYPI, I RECOMMEND SKIPPING THIS!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If we can add the folder that contains our package folder to our Python path, we can import our package from anywhere on our local machine. \n",
    "\n",
    "\n",
    "- Code example from:\n",
    "    - https://stackoverflow.com/questions/3387695/add-to-python-path-mac-os-x\n",
    "\n",
    "> NOTE: rename the files referenced below to match your actual folder names.\n",
    "\n",
    "___\n",
    "\n",
    "- The `cohort_package` folder with the `__init__.py` file is in another repo.\n",
    "    - On my local machine the path to the parent folder is:  \"/Users/codingdojo/Documents/GitHub/_COHORT_NOTES/022221FT/Online-DS-FT-022221-Cohort-Notes/py_files/\"\n",
    "\n",
    "\n",
    "- Add the following to ~/.bash_profile, replacing the filepath \"/Users....py_files/\" with your local folder path to the PARENT FOLDER of the package folder.\n",
    "\n",
    "\n",
    "- The following goes into the following file:\n",
    "    - REMINDER: `~` = your user folder.\n",
    "        - e.g. \"/Users/james/\"\n",
    "    - For windows:\n",
    "        - `~/.bash_profile`\n",
    "    - For Mac:\n",
    "        - If the terminal says \"`zsh`\" on the top of the window:\n",
    "            - `~/.zshrc`\n",
    "        - If the terminal says \"`bash`\" on the top of the window:\n",
    "            - `~/.bash_profile`\n",
    "        \n",
    "```bash\n",
    "## After activating dojo-env\n",
    "conda activate dojo-env\n",
    "export PYTHONPATH=\"$PYTHONPATH:/Users/james/Documents/GitHub/My_Repo/\"\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If it works properly. once you start a new terminal window, you should be able to import your package anywhere on your computer."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dojo-env)",
   "language": "python",
   "name": "dojo-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "271.996px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
